# -*- coding: utf-8 -*-
"""K-Means-Clustering-Algorithms-for-Customer-Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11aHMZRXl83yA-uU79CnfoQAqC9sAY37w
"""

# Import important packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl

# Commented out IPython magic to ensure Python compatibility.
# Plot styling
import seaborn as sns; sns.set()  # for plot styling
# %matplotlib inline
plt.rcParams['figure.figsize'] = (16, 9)
mpl.style.use('ggplot') # for ggplot-like style

# Read the data
cdata=pd.read_csv('CLV.csv')

cdata.head()

len(cdata)

"""## Exploratory Analysis"""

# Descriptive statistics of the dataset
cdata.describe()

# Visualize data
plot_spend=sns.distplot(cdata['SPEND'], color="#3498db")
plot_income=sns.distplot(cdata['INCOME'], color="#e74c3c")
plt.xlabel('Income / spend')

#Violin plot of Income and Spend
f, axes = plt.subplots(1,2, figsize=(12,6), sharex=True, sharey=True)
v1 = sns.violinplot(data=cdata, x='INCOME', color="skyblue",ax=axes[0])
v2 = sns.violinplot(data=cdata, x='SPEND',color="lightgreen", ax=axes[1])
v1.set(xlim=(0,420))

cdata

cdata.to_numpy()

#Using the elbow method to find the optimum number of clusters
from sklearn.cluster import KMeans
wcss = [] #minimizing within cluster sum of square
X=cdata.to_numpy()
for i in range(1,11):
    km=KMeans(n_clusters=i,init='k-means++', max_iter=300, n_init=10, random_state=0)
    #n_init set the number of time the k-means algorithm will be run with different centroid seeds.
    #k-means++ provides a smart initialization. This method tries to spread out the initial set of centroids so that they are not too close together.
    #k-means++ is known to improve the quality of local optima and lower average runtime.
    #max_iter set the maximum number of iterations of the k-means algorithm for a single run.
    #About random_state: If random_state is an integer, then it is used to seed a new RandomState object.
    km.fit(X)
    wcss.append(km.inertia_)
plt.plot(range(1,11),wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('wcss')
plt.show()

"""Based on the elbow plot, we could choose 4,5 or 6 clusters. Let us try both the number of clusters and visualize the clusters to decide on the final number of clusters.

## Model Fitting

### Fitting the k-means to the dataset with k=4
"""

a = np.array([[1, 2], [1, 4], [1, 0],
            [10, 2], [10, 4], [10, 0]])

a

##Fitting kmeans to the dataset with k=4
km4=KMeans(n_clusters=4,init='k-means++', max_iter=300, n_init=10, random_state=0)
y_means = km4.fit_predict(X) #fit_predict compute cluster centers and predict cluster index for each sample.
# y_means are the predicted cluster indexes. Cluster idexes are from 0-3 since there are only 4 clusters

y_means

X[y_means==3]

X[y_means==3,0]

X[y_means==3,1]

km4.cluster_centers_

#Visualizing the clusters for k=4
plt.scatter(X[y_means==0,0],X[y_means==0,1],s=50, c='purple',label='Cluster1') #s : scalar or array_like, shape (n, ),means the size of each scatter
plt.scatter(X[y_means==1,0],X[y_means==1,1],s=50, c='blue',label='Cluster2')
plt.scatter(X[y_means==2,0],X[y_means==2,1],s=50, c='green',label='Cluster3')
plt.scatter(X[y_means==3,0],X[y_means==3,1],s=50, c='cyan',label='Cluster4')
#X[y_means==3,0] returns the x axis (income) value when y_means==3;
#X[y_means==3,1] returns the y axis (spend) value when y_means==3;

plt.scatter(km4.cluster_centers_[:,0], km4.cluster_centers_[:,1],s=200,marker='s', c='red', alpha=0.7, label='Centroids')
#plt.scatter(km4.cluster_centers_[:,0] returns the first column and all rows
#km4.cluster_centers_[1,:] returns the values of the first row and all columns

plt.title('Customer segments')
plt.xlabel('Annual income of customer')
plt.ylabel('Annual spend from customer on site')
plt.legend()
plt.show()

"""The plot shows the distribution of the 4 clusters. We could interpret them as the following customer segments:

Cluster 1: Customers with medium annual income and low annual spend

Cluster 2: Customers with high annual income and medium to high annual spend

Cluster 3: Customers with low annual income

Cluster 4: Customers with medium annual income but high annual spend

Cluster 4 straight away is one potential customer segment. However, Cluster 2 and 3 can be segmented further to arrive at a more specific target customer group. Let us now look at how the clusters are created when k=6:

### Fitting kmeans to the dataset with k=6
"""

##Fitting kmeans to the dataset with k=6
km6=KMeans(n_clusters=6,init='k-means++', max_iter=300, n_init=10, random_state=0)
y_means = km6.fit_predict(X) #fit_predict compute cluster centers and predict cluster index for each sample.
# y_means are the predicted cluster indexes. Cluster idexes are from 0-3 since there are only 4 clusters

#Visualizing the clusters for k=6
plt.scatter(X[y_means==0,0],X[y_means==0,1],s=50, c='purple',label='Cluster1') #s : scalar or array_like, shape (n, ),means the size of each scatter
plt.scatter(X[y_means==1,0],X[y_means==1,1],s=50, c='blue',label='Cluster2')
plt.scatter(X[y_means==2,0],X[y_means==2,1],s=50, c='green',label='Cluster3')
plt.scatter(X[y_means==3,0],X[y_means==3,1],s=50, c='cyan',label='Cluster4')
#X[y_means==3,0] returns the x axis (income) value when y_means==3;
#X[y_means==3,1] returns the y axis (spend) value when y_means==3;
plt.scatter(X[y_means==4,0],X[y_means==4,1],s=50, c='magenta',label='Cluster5')
plt.scatter(X[y_means==5,0],X[y_means==5,1],s=50, c='orange',label='Cluster6')

plt.scatter(km6.cluster_centers_[:,0], km6.cluster_centers_[:,1],s=200,marker='s', c='red', alpha=0.7, label='Centroids')
#plt.scatter(km6.cluster_centers_[:,0] returns the first column and all rows
#km6.cluster_centers_[1,:] returns the values of the first row and all columns

plt.title('Customer segments')
plt.xlabel('Annual income of customer')
plt.ylabel('Annual spend from customer on site')
plt.legend()
plt.show()

"""Setting the number of clusters to 6 seems to provide a more meaningful customer segmentation.


Cluster 1: Medium income, low annual spend
    
Cluster 2: Low income, low annual spend
    
Cluster 3: High income, high annual spend
    
Cluster 4: Low income, high annual spend
    
Cluster 5: Medium income, medium annual spend
    
Cluster 6: Very high income, high annual spend


Thus it is evident that 6 clusters provides a more meaningful segmentation of the customers.

## Marketing strategies for the customer segments

Based on the 6 clusters, we could formulate marketing strategies relevant to each cluster:
A typical strategy would focus certain promotional efforts for the high value customers of Cluster 6 & Cluster 3.

- A typical strategy would focus certain promotional efforts for the high value customers of Cluster 6 & Cluster 3.


- Cluster 4 is a unique customer segment, where in spite of their relatively lower annual income, these customers tend to spend more on the site, indicating their loyalty. There could be some discounted pricing based promotional campaigns for this group so as to retain them.


- For Cluster 2 where both the income and annual spend are low, further analysis could be needed to find the reasons for the lower spend and price-sensitive strategies could be introduced to increase the spend from this segment.


- Customers in clusters 1 is not spending enough on the site in spite of a good annual income â€” further analysis of these segments could lead to insights on the satisfaction / dissatisfaction of these customers or lesser visibility of the e-commerce site to these customers. Strategies could be evolved accordingly.
"""